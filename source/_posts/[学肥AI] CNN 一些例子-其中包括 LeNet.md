---
title: CNN ä¸€äº›ä¾‹å­-å…¶ä¸­åŒ…æ‹¬ LeNet
date: 2024-08-02 10:18:38
tags: 
    - å­¦è‚¥AI
    - CNN
    - æ·±åº¦å­¦ä¹ 
    - LeNet
categories: å­¦è‚¥AI
description: "ç›´æ¥åº”ç”¨ CNN æ¥è§£å†³å®é™…é—®é¢˜ï¼ŒåŠ¨æ‰‹æ“ä½œæ‰æ˜¯å­¦ä¹ çš„æ ¹æœ¬"
cover: https://qiniu.oldzhangtech.com/cover/%E5%A4%A7%E8%B0%B7%E7%BF%94%E5%B9%B3%202.jpg
---

## èƒŒæ™¯é—®é¢˜
å‰æ–‡ä¸­å·²ç»å¯¹ CNN ç»„ä»¶ ä»¥åŠæ•´ä½“çš„æ•°æ®æµåŠ¨æœ‰äº†è§£ï¼Œæœ‰éœ€è¦çš„å¯ä»¥ç¿»çœ‹ä¹‹å‰çš„[æ–‡ç« ](https://blog.csdn.net/weixin_49113487/article/details/140717493?spm=1001.2014.3001.5501)ï¼Œåé¢æˆ‘ä»¬ç›´æ¥åº”ç”¨ CNN æ¥è§£å†³å®é™…é—®é¢˜ï¼ŒåŠ¨æ‰‹æ“ä½œæ‰æ˜¯å­¦ä¹ çš„æ ¹æœ¬ã€‚

æœ¬ç¯‡çš„æ‰€æœ‰çš„ä¾‹å­ï¼Œè¯¦ç»†çš„ `ipynb` éƒ½å¯ä»¥ä»ä¸‹é¢é“¾æ¥ä¸­æ‰¾åˆ°ã€‚ NNvsCNN [ipynb é“¾æ¥](https://gitee.com/oldmanzhang/resource_machine_learning/blob/master/deep_learning/cnn_compareNN.ipynb)ï¼Œè¯†åˆ«å›¾å½¢ [ipynb é“¾æ¥](https://gitee.com/oldmanzhang/resource_machine_learning/blob/master/deep_learning/cnn_classify_triangleCycleRectangle.ipynb)ã€‚
## NN vs CNN
æœ¬ä¾‹å­çš„ç›®çš„æ˜¯ï¼šåŒæ ·é¢å¯¹ `mnist` æ‰‹å†™æ•°å­—æ•°æ®é›†çš„æ—¶å€™ï¼Œå¯¹æ¯” ä½¿ç”¨ `NN` å’Œ ä½¿ç”¨ `CNN` ï¼Œçœ‹ä¸€ä¸‹ä»–ä»¬è¡¨ç°çš„å·®å¼‚ã€‚å¯è¿è¡Œæ–‡ä»¶ `ipynb` çš„[é“¾æ¥](https://gitee.com/oldmanzhang/resource_machine_learning/blob/master/deep_learning/cnn_compareNN.ipynb)ã€‚
### prepare data
```python
import torch
import torchvision

# %%
transformation = torchvision.transforms.ToTensor()
# æ‰§è¡Œè°ƒæ•´æ–‡ä»¶çš„ä½ç½®
train_dataset = torchvision.datasets.MNIST(root='../data/mnist/', train=True, download=True, transform=transformation)
test_dataset = torchvision.datasets.MNIST(root='../data/mnist/', train=False, download=True, transform=transformation)

batch_size = 64
train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)
```
### NN çš„å®ç°
```python


import matplotlib.pyplot as plt
from torchinfo import summary
import torch.nn as nn
from tqdm import * # tqdmç”¨äºæ˜¾ç¤ºè¿›åº¦æ¡å¹¶è¯„ä¼°ä»»åŠ¡æ—¶é—´å¼€é”€
import numpy as np
import sys


class NNet(nn.Module):
    def __init__(self, input_size, hidden_sizes, output_size):
        super().__init__()
        
        self.fcin = nn.Linear(input_size, hidden_sizes[0]) if hidden_sizes else nn.Linear(input_size, output_size)
        self.fcout = nn.Linear(hidden_sizes[-1], output_size) if hidden_sizes else nn.Identity()
        self.relu = nn.ReLU()

        # Create a list of intermediate layers
        layers = []
        for i in range(len(hidden_sizes) - 1):
            layers.append(nn.Linear(hidden_sizes[i], hidden_sizes[i+1]))
            layers.append(nn.ReLU())
        # Convert the list of layers into a Sequential module
        self.hidden_layers = nn.Sequential(*layers)

    def forward(self, x):
     
        out = self.fcin(x)
        out = self.relu(out)
        
        # Pass through the hidden layers
        if len(self.hidden_layers) > 0:
            out = self.hidden_layers(out)
        
        # å°†ä¸Šä¸€æ­¥ç»“æœä¼ é€’ç»™fcout
        out = self.fcout(out)
        # è¿”å›ç»“æœ
        return out

# %%
input_size = 28*28
output_size = 10
model = NNet(input_size, [512, 512], output_size)
print(summary(model))
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

def evaluate(model, data_loader):
#     è¯„ä¼°
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for x, y in data_loader:
            x = x.view(-1, input_size)
            logits = model(x)
#             _ æ˜¯ value ï¼Œ predicted æ˜¯ index
            _, predicted = torch.max(logits.data, 1)
            total += y.size(0)
            correct += (predicted == y).sum().item()
    return correct / total

loss_history = []  # åˆ›å»ºæŸå¤±å†å²è®°å½•åˆ—è¡¨
acc_history = []   # åˆ›å»ºå‡†ç¡®ç‡å†å²è®°å½•åˆ—è¡¨
num_epochs = 10
for epoch in tqdm(range(num_epochs), file=sys.stdout):
    # è®°å½•æŸå¤±å’Œé¢„æµ‹æ­£ç¡®æ•°
    total_loss = 0
    total_correct = 0
    
    model.train()
    for images, labels in train_dataloader:
        # å°†å›¾åƒå’Œæ ‡ç­¾è½¬æ¢æˆå¼ é‡
        # [64, 1, 28, 28] -> [64, 784]
        images = images.view(-1, 28*28)  
        labels = labels.long()
        
        # å‰å‘ä¼ æ’­
        outputs = model(images)
        loss = criterion(outputs, labels)
        
        # è®°å½•è®­ç»ƒé›†loss
        total_loss += loss.item()
        
        # åå‘ä¼ æ’­å’Œä¼˜åŒ–
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
    loss_history.append(np.log10(total_loss))    
    accuracy = evaluate(model, test_dataloader)
    acc_history.append(accuracy)
    if(epoch%3 == 0):
        print(f'Epoch {epoch+1}: test accuracy = {acc_history[-1]:.2f}')


# ä½¿ç”¨Matplotlibç»˜åˆ¶æŸå¤±å’Œå‡†ç¡®ç‡çš„æ›²çº¿å›¾
import matplotlib.pyplot as plt
plt.plot(loss_history, label='loss')
plt.plot(acc_history, label='accuracy')
plt.legend()
plt.show()

# è¾“å‡ºå‡†ç¡®ç‡
print("Accuracy:", acc_history[-1])
```
![image.png](https://qiniu.oldzhangtech.com/mdpic/55ff4334-4439-494f-aa82-709af8e79db0_d98edf1a-29fd-456c-8a2e-8e4b28464ff6.png)
```python
# éƒ¨åˆ†çš„è¾“å‡º
Accuracy: 0.9422
```
### CNN çš„å®ç°
```python
# å¯¼å…¥å¿…è¦çš„åº“ï¼Œtorchinfoç”¨äºæŸ¥çœ‹æ¨¡å‹ç»“æ„
import torch
import torch.nn as nn
from torchinfo import summary

# å®šä¹‰LeNetçš„ç½‘ç»œç»“æ„
class SimpleCnnNet(nn.Module):
    def __init__(self, num_classes=10):
        super(SimpleCnnNet, self).__init__()
#         æ­¥é•¿é»˜è®¤ä¸º1ï¼Œå¡«å……é»˜è®¤ä¸º0 ä¸€å®šè¦è®°å¾—
        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)
        # å·ç§¯å±‚2ï¼šè¾“å…¥6ä¸ªé€šé“ï¼Œè¾“å‡º16ä¸ªé€šé“ï¼Œå·ç§¯æ ¸å¤§å°ä¸º5x5
        
        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)
        # å…¨è¿æ¥å±‚1ï¼šè¾“å…¥16x4x4=256ä¸ªèŠ‚ç‚¹ï¼Œè¾“å‡º120ä¸ªèŠ‚ç‚¹
        self.fc1 = nn.Linear(in_features=16 * 4 * 4, out_features=120)
        # å…¨è¿æ¥å±‚2ï¼šè¾“å…¥120ä¸ªèŠ‚ç‚¹ï¼Œè¾“å‡º84ä¸ªèŠ‚ç‚¹
        self.fc2 = nn.Linear(in_features=120, out_features=84)
        # è¾“å‡ºå±‚ï¼šè¾“å…¥84ä¸ªèŠ‚ç‚¹ï¼Œè¾“å‡º10ä¸ªèŠ‚ç‚¹
        self.fc3 = nn.Linear(in_features=84, out_features=num_classes)

    def forward(self, x):
        # ä½¿ç”¨ReLUæ¿€æ´»å‡½æ•°ï¼Œå¹¶è¿›è¡Œæœ€å¤§æ± åŒ–
        x = torch.relu(self.conv1(x)) 
        # input: 1,28,28, output: 6,24,24
        # output è®¡ç®—é€»è¾‘ï¼š(28-5+2*0)/1 + 1 = 24
        x = nn.functional.max_pool2d(x, kernel_size=2)  # output: 6,12,12
        # ä½¿ç”¨ReLUæ¿€æ´»å‡½æ•°ï¼Œå¹¶è¿›è¡Œæœ€å¤§æ± åŒ–
        x = torch.relu(self.conv2(x))  
        # input: 6,12,12, output: 16,8,8
        # output è®¡ç®—é€»è¾‘ï¼š(12-5+2*0)/1 + 1 = 8
        x = nn.functional.max_pool2d(x, kernel_size=2)  
        # output: 16,4,4
        
        # å°†å¤šç»´å¼ é‡å±•å¹³ä¸ºä¸€ç»´å¼ é‡
        x = x.view(-1, 16 * 4 * 4)
        # å…¨è¿æ¥å±‚
        x = torch.relu(self.fc1(x))
        # å…¨è¿æ¥å±‚
        x = torch.relu(self.fc2(x))
        # å…¨è¿æ¥å±‚
        x = self.fc3(x)
        return x
    
# æŸ¥çœ‹æ¨¡å‹ç»“æ„åŠå‚æ•°é‡ï¼Œinput_sizeè¡¨ç¤ºç¤ºä¾‹è¾“å…¥æ•°æ®çš„ç»´åº¦ä¿¡æ¯
print(summary(SimpleCnnNet(), input_size=(1, 1, 28, 28)))

# å¯¼å…¥å¿…è¦çš„åº“
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
from tqdm import * # tqdmç”¨äºæ˜¾ç¤ºè¿›åº¦æ¡å¹¶è¯„ä¼°ä»»åŠ¡æ—¶é—´å¼€é”€
import numpy as np
import sys

# è®¾ç½®éšæœºç§å­
torch.manual_seed(0)

# å®šä¹‰æ¨¡å‹ã€ä¼˜åŒ–å™¨ã€æŸå¤±å‡½æ•°
model = SimpleCnnNet()
optimizer = optim.SGD(model.parameters(), lr=0.02)
criterion = nn.CrossEntropyLoss()

# è®¾ç½®æ•°æ®å˜æ¢å’Œæ•°æ®åŠ è½½å™¨
transform = transforms.Compose([
    transforms.ToTensor(),  # å°†æ•°æ®è½¬æ¢ä¸ºå¼ é‡
])


# è®¾ç½®epochæ•°å¹¶å¼€å§‹è®­ç»ƒ
num_epochs = 10  # è®¾ç½®epochæ•°
loss_history = []  # åˆ›å»ºæŸå¤±å†å²è®°å½•åˆ—è¡¨
acc_history = []   # åˆ›å»ºå‡†ç¡®ç‡å†å²è®°å½•åˆ—è¡¨

# tqdmç”¨äºæ˜¾ç¤ºè¿›åº¦æ¡å¹¶è¯„ä¼°ä»»åŠ¡æ—¶é—´å¼€é”€
for epoch in tqdm(range(num_epochs), file=sys.stdout):
    # è®°å½•æŸå¤±å’Œé¢„æµ‹æ­£ç¡®æ•°
    total_loss = 0
    total_correct = 0
    
    # æ‰¹é‡è®­ç»ƒ
    model.train()
    for inputs, labels in train_dataloader:

        # é¢„æµ‹ã€æŸå¤±å‡½æ•°ã€åå‘ä¼ æ’­
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        
        # è®°å½•è®­ç»ƒé›†loss
        total_loss += loss.item()
    
    # æµ‹è¯•æ¨¡å‹ï¼Œä¸è®¡ç®—æ¢¯åº¦
    model.eval()
    with torch.no_grad():
        for inputs, labels in test_dataloader:

            # é¢„æµ‹
            outputs = model(inputs)
            # è®°å½•æµ‹è¯•é›†é¢„æµ‹æ­£ç¡®æ•°
            total_correct += (outputs.argmax(1) == labels).sum().item()
        
    # è®°å½•è®­ç»ƒé›†æŸå¤±å’Œæµ‹è¯•é›†å‡†ç¡®ç‡
    loss_history.append(np.log10(total_loss))  # å°†æŸå¤±åŠ å…¥æŸå¤±å†å²è®°å½•åˆ—è¡¨ï¼Œç”±äºæ•°å€¼æœ‰æ—¶è¾ƒå¤§ï¼Œè¿™é‡Œå–å¯¹æ•°
    acc_history.append(total_correct / len(test_dataset))# å°†å‡†ç¡®ç‡åŠ å…¥å‡†ç¡®ç‡å†å²è®°å½•åˆ—è¡¨
    
    # æ‰“å°ä¸­é—´å€¼
    if epoch % 2 == 0:
        tqdm.write("Epoch: {0} Loss: {1} Acc: {2}".format(epoch, loss_history[-1], acc_history[-1]))

# ä½¿ç”¨Matplotlibç»˜åˆ¶æŸå¤±å’Œå‡†ç¡®ç‡çš„æ›²çº¿å›¾
import matplotlib.pyplot as plt
plt.plot(loss_history, label='loss')
plt.plot(acc_history, label='accuracy')
plt.legend()
plt.show()

# è¾“å‡ºå‡†ç¡®ç‡
print("Accuracy:", acc_history[-1])
```

![image.png](https://qiniu.oldzhangtech.com/mdpic/4413e664-0d64-4025-8085-61dfb55dd43d_069afa8c-7ef4-416f-ac1b-9f499a31c7a5.png)
```python
# éƒ¨åˆ†çš„è¾“å‡º
Accuracy: 0.9832
```
### å¯¹æ¯”æ•ˆæœ
```python
# ä½¿ç”¨Matplotlibç»˜åˆ¶æŸå¤±å’Œå‡†ç¡®ç‡çš„æ›²çº¿å›¾
import matplotlib.pyplot as plt
plt.plot(nn_loss_history, label='nn loss')
plt.plot(nn_acc_history, label='nn accuracy')
plt.plot(cnn_loss_history, label='cnn loss')
plt.plot(cnn_acc_history, label='cnn accuracy')
plt.legend()
plt.show()

# è¾“å‡ºå‡†ç¡®ç‡
print("ACCURACY:")
print("nn:", nn_acc_history[-1])
print("cnn:", cnn_acc_history[-1])

# è®¡ç®—å‚æ•°é‡
def count_parameters(model):
    return sum(p.numel() for p in model.parameters() if p.requires_grad)

nn_total_params = count_parameters(nn_model)
cnn_total_params = count_parameters(cnn_model)


print("count of PARAMETERS:")
print("nn:", nn_total_params)
print("cnn:", cnn_total_params)
```
![image.png](https://qiniu.oldzhangtech.com/mdpic/3e483fa6-5eec-4eb5-8ce9-6cfc2967bd9b_3874b442-7387-4608-bf5a-0ff2e2b34337.png)
```python
ACCURACY:
nn: 0.9422
cnn: 0.9832

count of PARAMETERS:
nn: 669706
cnn: 44426
```

ğŸ”¥ ä»å›¾ä¸­å¯ä»¥çœ‹åˆ° `CNN` æ¯” `NN` çš„ **å‡†ç¡®åº¦æ›´åŠ é«˜**ï¼Œ åŒæ—¶ä»–çš„ä½¿ç”¨çš„ **å‚æ•°é‡ä¼šæ›´åŠ çš„å°‘**ã€‚

ğŸ’¡ å½“ç„¶æ¨¡å‹åº”ç”¨ä¸åŒçš„è¶…å‚æ•°ä¼šæœ‰ä¸åŒçš„æ•ˆæœï¼Œå¯ä»¥å¯¹ `NN` å’Œ `CNN` è¿›è¡Œä¿®æ”¹ï¼Œçœ‹ä¸€ä¸‹æ•ˆæœå¦‚ä½•ã€‚åŒæ—¶ [é“¾æ¥](https://gitee.com/oldmanzhang/resource_machine_learning/blob/master/deep_learning/cnn_compareNN.ipynb) ä¸­å·²ç»æœ‰ `girdSearch` çš„æ–¹æ³•ï¼Œç”¨äºå¯»æ‰¾æœ€ä½³çš„ `NN` å‚æ•°ã€‚

## LeNet ç½‘ç»œ è¯†åˆ«æ‰‹å†™æ•°å­—
å‚è€ƒäº†åˆ«äººçš„å„ç§å·ç§¯ç¥ç»ç½‘ç»œçš„æ—¶é—´çº¿è´´å›¾ã€‚
![](https://qiniu.oldzhangtech.com/mdpic/20431588-e607-4106-817c-68d54848a902_83fc8c68-cce1-4663-85a0-e94f939f9052.png)
`LeNet` ä¸ºå·ç§¯ç¥ç»ç½‘ç½‘ç»œå¥ å®šäº†åŸºçŸ³ã€‚æ‰€æœ‰çš„åç»­çš„ç½‘ç»œéƒ½æ˜¯åŸºäºè¿™ä¸ªç½‘ç»œè¿›è¡Œæ‰©å±•çš„ã€‚
### æ•´ä½“æ¡†æ¶
![](https://qiniu.oldzhangtech.com/mdpic/b990ca3c-7939-4610-b9d8-cafc9586a8bd_5119f828-a66b-4e1d-a03b-7703add2107a.png)
`LeNet` æ˜¯ç”± å¤šä¸ªå·ç§¯å±‚ï¼Œæ± åŒ–å±‚ï¼Œå…¨è¿æ¥å±‚ ç»„åˆæ„å»ºè€Œæ¥ã€‚
ç»“æ„å¹¶ä¸å¤æ‚ï¼Œä¸‹é¢å°±å¯ä»¥æ‰‹åŠ¨å»å®ç°è¿™ä¸ªç½‘ç»œã€‚å¦‚æœå¯¹ `å·ç§¯`ï¼Œ`æ± åŒ–` å¹¶ä¸ç†Ÿæ‚‰çš„ï¼Œå¯ä»¥å‰å¾€ [æ–‡ç« ](https://blog.csdn.net/weixin_49113487/article/details/140717493) è¿›è¡Œäº†è§£ã€‚
### æ‰‹å†™ LeNet ç½‘ç»œ
å…¶å®æ‰‹å†™ `LeNet`  å°±æ˜¯ ä¸Šè¿°ä¾‹å­ä¸­çš„ `CNN` çš„ `SimpleCnnNet`ã€‚ä¸‹é¢åˆ—å‡ºéƒ¨åˆ†çš„ä»£ç ç‰‡æ®µã€‚

```python
class SimpleCnnNet(nn.Module):
    def __init__(self, num_classes=10):
        super(SimpleCnnNet, self).__init__()
#         æ­¥é•¿é»˜è®¤ä¸º1ï¼Œå¡«å……é»˜è®¤ä¸º0 ä¸€å®šè¦è®°å¾—
        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)
        # å·ç§¯å±‚2ï¼šè¾“å…¥6ä¸ªé€šé“ï¼Œè¾“å‡º16ä¸ªé€šé“ï¼Œå·ç§¯æ ¸å¤§å°ä¸º5x5 
        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)
        # å…¨è¿æ¥å±‚1ï¼šè¾“å…¥16x4x4=256ä¸ªèŠ‚ç‚¹ï¼Œè¾“å‡º120ä¸ªèŠ‚ç‚¹
        self.fc1 = nn.Linear(in_features=16 * 4 * 4, out_features=120)
        # å…¨è¿æ¥å±‚2ï¼šè¾“å…¥120ä¸ªèŠ‚ç‚¹ï¼Œè¾“å‡º84ä¸ªèŠ‚ç‚¹
        self.fc2 = nn.Linear(in_features=120, out_features=84)
        # è¾“å‡ºå±‚ï¼šè¾“å…¥84ä¸ªèŠ‚ç‚¹ï¼Œè¾“å‡º10ä¸ªèŠ‚ç‚¹
        self.fc3 = nn.Linear(in_features=84, out_features=num_classes)

    def forward(self, x):
        # ä½¿ç”¨ReLUæ¿€æ´»å‡½æ•°ï¼Œå¹¶è¿›è¡Œæœ€å¤§æ± åŒ–
        x = torch.relu(self.conv1(x)) 
        # input: 1,28,28, output: 6,24,24
        # output è®¡ç®—é€»è¾‘ï¼š(28-5+2*0)/1 + 1 = 24
        x = nn.functional.max_pool2d(x, kernel_size=2)  # output: 6,12,12
        # ä½¿ç”¨ReLUæ¿€æ´»å‡½æ•°ï¼Œå¹¶è¿›è¡Œæœ€å¤§æ± åŒ–
        x = torch.relu(self.conv2(x))  
        # input: 6,12,12, output: 16,8,8
        # output è®¡ç®—é€»è¾‘ï¼š(12-5+2*0)/1 + 1 = 8
        x = nn.functional.max_pool2d(x, kernel_size=2)  
        # output: 16,4,4
        
        # å°†å¤šç»´å¼ é‡å±•å¹³ä¸ºä¸€ç»´å¼ é‡
        x = x.view(-1, 16 * 4 * 4)
        # å…¨è¿æ¥å±‚
        x = torch.relu(self.fc1(x))
        # å…¨è¿æ¥å±‚
        x = torch.relu(self.fc2(x))
        # å…¨è¿æ¥å±‚
        x = self.fc3(x)
        return x
```
ç”±ä¸Šé¢å®šä¹‰çš„æ¨¡å‹çš„ç»“æ„å¾—çŸ¥ï¼š
`Feature extraction`ï¼š ç”± 2 *ã€å·ç§¯ *  æ¿€æ´»   * æ± åŒ–ã€‘ç»„æˆï¼Œæ¯å±‚çš„å·ç§¯å’Œæ± åŒ–çš„å‚æ•°æœ‰ä¸åŒã€‚ç”¨äºæŠ½å–ç‰¹å¾ã€‚
`Classification`ï¼š ç”± 2 *ã€å…¨è¿æ¥å±‚ * æ¿€æ´»ã€‘ ç»„æˆã€‚å¯¹ç‰¹å¾è¿›è¡Œé€»è¾‘å…³è”ã€‚

## è¯†åˆ«ä¸‰è§’å½¢/åœ†å½¢/æ­£æ–¹å½¢
ç›®çš„ï¼šç”Ÿæˆéšæœºçš„ ä¸‰è§’å½¢/åœ†å½¢/æ­£æ–¹å½¢ çš„é»‘ç™½å›¾æ•°æ®é›†ï¼Œå¹¶ç”¨ CNN çš„æ¨¡å‹è¯†åˆ«ä»–ä»¬ã€‚å¯è¿è¡Œ ipynb çš„æ–‡ä»¶[é“¾æ¥](https://gitee.com/oldmanzhang/resource_machine_learning/blob/master/deep_learning/cnn_classify_triangleCycleRectangle.ipynb)ã€‚
_Prepare data_
```python
# !pip install opencv-python
import cv2
import numpy as np
import matplotlib.pyplot as plt
import os

def create_shape(shape, img_size=1000):
    img = np.zeros((img_size, img_size), dtype=np.uint8)
    if shape == 'circle':
        radius = np.random.randint(img_size // 8, img_size // 4)
        center = (np.random.randint(radius, img_size - radius), np.random.randint(radius, img_size - radius))
        cv2.circle(img, center, radius, 255, -1)
    elif shape == 'triangle':
        pt1 = (np.random.randint(0, img_size), np.random.randint(0, img_size))
        pt2 = (np.random.randint(0, img_size), np.random.randint(0, img_size))
        pt3 = (np.random.randint(0, img_size), np.random.randint(0, img_size))
        points = np.array([pt1, pt2, pt3])
        cv2.drawContours(img, [points], 0, 255, -1)
    elif shape == 'rectangle':
        pt1 = (np.random.randint(0, img_size // 2), np.random.randint(0, img_size // 2))
        pt2 = (np.random.randint(img_size // 2, img_size), np.random.randint(img_size // 2, img_size))
        cv2.rectangle(img, pt1, pt2, 255, -1)
    return img

def generate_dataset(num_samples=1000, img_size=1000):
    shapes = ['circle', 'triangle', 'rectangle']
    data = []
    labels = []
    for _ in range(num_samples):
        shape = np.random.choice(shapes)
        img = create_shape(shape, img_size)
        data.append(img)
        labels.append(shapes.index(shape))
    return np.array(data), np.array(labels)
```

å¯è§†åŒ–å›¾åƒã€‚
```python
# Visualize some samples
# img_size = 200 æ˜¯æ¯”è¾ƒå¥½çš„ä½“ç°å‡º å½¢çŠ¶
fig, axes = plt.subplots(1, 3, figsize=(10, 5))
for i, shape in enumerate(['circle', 'triangle', 'rectangle']):
    axes[i].imshow(create_shape(shape, img_size=200), cmap='gray')
    axes[i].set_title(shape)
    axes[i].axis('off')
plt.show()
```
![image.png](https://qiniu.oldzhangtech.com/mdpic/4a51309b-3fe5-4280-9bbd-da97b8c6925d_bf9181d6-8b22-499c-a013-52ec993b5c47.png)

éšæœºæ£€æŸ¥æ•°æ®é›†ï¼Œæ£€æŸ¥æ•°æ®æ˜¯å¦åˆç†ã€‚
```python
num = 5
ran_indexes = np.random.randint(0, len(data), num)
fig, axes = plt.subplots(1, num, figsize=(10, 5))
for i in range(num):
    axes[ i].imshow(data[ran_indexes[i]], cmap='gray')  ## 'Axes' object is not subscriptable
    axes[ i].set_title(f'index : {ran_indexes[i]} {labels[ran_indexes[i]]}')
    axes[ i].axis('off')
plt.show()
# 0: cycle, 1: triangle, 2: rectangle
```
![image.png](https://qiniu.oldzhangtech.com/mdpic/0e26b843-b82c-4cb3-8617-54f7eb265e20_f96bca9b-901b-4724-bd06-6b9fab029a9a.png)

_define model_
```python
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms


class ShapeDataset(Dataset):
    def __init__(self, data, labels, transform=None):
        self.data = data
        self.labels = labels
        self.transform = transform

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        image = self.data[idx]
        label = self.labels[idx]
        
        if self.transform:
            image = self.transform(image)
        
        return image, label

class SimpleCNN(nn.Module):
    def __init__(self):
        super(SimpleCNN, self).__init__()
        # output:32*200*200
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)
        # output:32*50*50
        self.pool = nn.MaxPool2d(2, 2)
        # output:64*50*50
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)
        # output:128
        self.fc1 = nn.Linear(64 * 50 * 50, 128)  # Adjust input size for the new image size
        # output: 3
        self.fc2 = nn.Linear(128, 3)  # 3 classes: circle, triangle, rectangle

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 64 * 50 * 50)  # Flatten the tensor
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x
```

_train model_
```python
# Data transformation
transform = transforms.Compose([
    # transforms.Grayscale(num_output_channels=1),  # Ensure single channel for grayscale images
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

# Create the dataset and data loaders
train_dataset = ShapeDataset(data, labels, transform=transform)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)



# Instantiate the model
model = SimpleCNN()

# Define loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# validate dataset
val_data, val_labels = generate_dataset(num_samples=200, img_size=200)
val_dataset = ShapeDataset(val_data, val_labels, transform=transform)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)



# Training method
def train(model, train_loader, val_loader, criterion, optimizer, num_epochs):
    model.train()
    for epoch in range(num_epochs):
        running_loss = 0.0
        for _data, _labels in train_loader:
            # Zero the parameter gradients
            optimizer.zero_grad()

            # Forward pass
            outputs = model(_data)

            # print(_data.shape, _labels.shape, outputs.shape)

            loss = criterion(outputs, _labels)

            # Backward pass and optimize
            loss.backward()
            optimizer.step()

            # Print statistics
            running_loss += loss.item()

        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}')
        validate(model, val_loader, criterion)

    print('Finished Training')

# Validation method
def validate(model, val_loader, criterion):
    model.eval()  # Set the model to evaluation mode
    val_loss = 0.0
    correct = 0
    total = 0
    with torch.no_grad():
        for _data, _labels in val_loader:
            

            # Forward pass
            outputs = model(_data)

            # print(_data.shape, _labels.shape, outputs.shape)
            
            # Calculate accuracy
            _, predicted = torch.max(outputs, 1)
            total += _labels.size(0)
            correct += (predicted == _labels).sum().item()

            # Optional: Calculate loss if needed
            # loss = criterion(outputs, _labels)
            # val_loss += loss.item()

    # Optional: Calculate average loss if needed
    # avg_loss = val_loss / len(val_loader)
    accuracy = 100 * correct / total
    print(f'Accuracy: {accuracy:.2f}%')


# Train the model with validation
num_epochs = 20
train(model, train_loader, val_loader, criterion, optimizer, num_epochs)

'''
Epoch [17/20], Loss: 0.0005
Accuracy: 92.00%
Epoch [18/20], Loss: 0.0005
Accuracy: 92.00%
Epoch [19/20], Loss: 0.0004
Accuracy: 92.00%
Epoch [20/20], Loss: 0.0003
Accuracy: 92.00%
Finished Training
'''

```
_evalue_
```python
# Generate test data
test_data, test_labels = generate_dataset(num_samples=100, img_size=200)

# Create the test dataset and data loader
test_dataset = ShapeDataset(test_data, test_labels, transform=transform)
test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)

# Evaluate the model
model.eval()  # Set the model to evaluation mode
correct = 0
total = 0
with torch.no_grad():
    for inputs, labels in test_loader:
        # Ensure inputs have the correct shape
        inputs, labels = inputs.float(), labels
        outputs = model(inputs)
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print(f'Accuracy of the model on the test images: { correct / total:.2f}%')
'''
Accuracy of the model on the test images: 0.90%

'''
```
_NOTE_ï¼š å‡†ç¡®ç‡è¿˜æ˜¯å¯ä»¥çš„ã€‚

_æ¨ç†å¹¶ä¸”è§†è§‰éªŒè¯_
```python

# Visualize some test samples and their predictions
def visualize_predictions(inputs, labels, predictions):
    fig, axes = plt.subplots(1, 5, figsize=(15, 5))
    for i in range(5):
        axes[i].imshow(inputs[i].squeeze(), cmap='gray')
        axes[i].set_title(f'True: {labels[i]}, Pred: {predictions[i]}')
        axes[i].axis('off')
    plt.show()

# Generate test data
visual_data, visual_labels = generate_dataset(num_samples=5, img_size=200)

# Create the test dataset and data loader
visual_dataset = ShapeDataset(visual_data, visual_labels, transform=transform)
visual_loader = DataLoader(visual_dataset, batch_size=5, shuffle=False)

# torch.from_numpy(visual_data).float().unsqueeze(1).shape = 5,1,200,200
outputs = model(torch.from_numpy(visual_data).float().unsqueeze(1))
_, predictions = torch.max(outputs, 1)
visualize_predictions(visual_data, visual_labels, predictions.numpy())
```
![image.png](https://qiniu.oldzhangtech.com/mdpic/03db3b3d-0d90-4dac-9888-fcf3f9c809c2_39713376-9e7f-4693-93da-b60856f1a06f.png)



## NOTE
`CNN` æ˜¯ä¸€ç§æœ‰æ•ˆçš„ `è§£å†³ç©ºé—´` ä¿¡æ¯çš„æ·±åº¦å­¦ä¹ ç½‘ç»œï¼Œç‰¹åˆ«é€‚ç”¨äºå›¾åƒé—®é¢˜çš„è§£å†³ä¸­ã€‚

